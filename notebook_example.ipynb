{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ox4IxtyI1Cz"
      },
      "outputs": [],
      "source": [
        "# Googleドライブのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ライブラリのインポート"
      ],
      "metadata": {
        "id": "DPt8NnsdJkyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import csv\n",
        "import logging\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# 評価関数 ------------------------\n",
        "from sklearn.metrics import f1_score\n",
        "## f1_scoreは確率値のままでは評価できないので、カスタマイズが必要\n",
        "def f1_score_prob(y_true, y_pred, threshold=0.5):\n",
        "    return f1_score(y_true, np.where(y_pred > threshold, 1, 0))\n",
        "\n",
        "# モデル --------------------------\n",
        "import lightgbm as lgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "kF3geTNXJbFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ディレクトリ移動 ----------------------------------------------------\n",
        "BASE_PATH = '/content/drive/MyDrive/コンペティション/【練習問題】債務不履行リスクの低減'\n",
        "os.chdir(BASE_PATH)"
      ],
      "metadata": {
        "id": "JTSdL9BsLmy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## config.py\n",
        "- ディレクトリを作成\n",
        "    - `./feature/`：特徴量を保存\n",
        "    - `./model/`：モデル・計算ログを保存\n",
        "    - `./submission/`：提出ファイルを保存\n",
        "- 前処理\n",
        "- 前処理済みのデータを`.pkl`ファイルに保存\n",
        "    - `.pkl`のほうが読み込みが早い"
      ],
      "metadata": {
        "id": "gwGQkN4hJ7IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    # train,testのパスを指定 ---------------\n",
        "    train_path_csv = './data/train.csv'\n",
        "    test_path_csv = './data/test.csv'\n",
        "    # --------------------------------------\n",
        "    train_path = train_path_csv.replace('.csv', '.pkl')\n",
        "    test_path = test_path_csv.replace('.csv', '.pkl')\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def make_dir(self):\n",
        "        # ディレクトリ作成\n",
        "        os.makedirs('./feature', exist_ok=True)\n",
        "        os.makedirs('./model', exist_ok=True)\n",
        "        os.makedirs('./submission', exist_ok=True)\n",
        "        # csvファイル読み込み\n",
        "        train = pd.read_csv(self.train_path_csv)\n",
        "        test = pd.read_csv(self.test_path_csv)\n",
        "        # 前処理\n",
        "        train, test = self.preprocess(train, test)\n",
        "        # pickleファイル保存\n",
        "        pickle.dump(train, open(self.train_path, 'wb'))\n",
        "        pickle.dump(test, open(self.test_path, 'wb'))\n",
        "\n",
        "    def preprocess(self, train, test):\n",
        "        # 前処理をここに書く -----------\n",
        "        df_all = pd.concat([train, test])\n",
        "\n",
        "        df_all['term'] = df_all['term'].str.extract('(\\d+)', expand=False).astype('int')\n",
        "        grade_unq = sorted(df_all['grade'].unique())\n",
        "        df_all['grade'] = df_all['grade'].map({k:v for v,k in enumerate(grade_unq)})\n",
        "        df_all['employment_length'] = df_all['employment_length'].str.extract('(\\d+)', expand=False).fillna(0).astype('int')\n",
        "        dummy_purpose =  pd.get_dummies(df_all['purpose'], prefix='purpose')\n",
        "        dummy_apptype = pd.get_dummies(df_all['application_type'], prefix='application_type')\n",
        "        df_all['loan_status'] = df_all['loan_status'].map({'FullyPaid':0, 'ChargedOff':1})\n",
        "        df_all = pd.concat([df_all.drop(['purpose', 'application_type'], axis=1), dummy_purpose, dummy_apptype], axis=1)\n",
        "\n",
        "        train = df_all[~df_all['loan_status'].isnull()]\n",
        "        test = df_all[df_all['loan_status'].isnull()]\n",
        "        # ------------------------------\n",
        "        return train, test"
      ],
      "metadata": {
        "id": "xSct7b5mJ6cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## base.py\n",
        "特徴量・モデルクラスの基底クラス。これを継承してクラスを定義してください。"
      ],
      "metadata": {
        "id": "pwUeS0dfKxW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量定義の基底クラス\n",
        "class Feature:\n",
        "    \"\"\"docstringに特徴量の説明を記述\"\"\"\n",
        "    prefix = ''\n",
        "    suffix = ''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.name = self.__class__.__name__\n",
        "        self.train = pd.read_pickle(Config.train_path)\n",
        "        self.test = pd.read_pickle(Config.test_path)\n",
        "\n",
        "    def run(self):\n",
        "        self.create_features()\n",
        "        prefix = self.prefix + '_' if self.prefix else ''\n",
        "        suffix = '_' + self.suffix if self.suffix else ''\n",
        "        self.train.columns = prefix + self.train.columns + suffix\n",
        "        self.test.columns = prefix + self.test.columns + suffix\n",
        "        return self\n",
        "\n",
        "    def create_features(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def save(self):\n",
        "        self.train.to_pickle(f'./feature/{self.name}_train.pkl')\n",
        "        self.test.to_pickle(f'./feature/{self.name}_test.pkl')\n",
        "\n",
        "    def create_memo(self):\n",
        "        file_path = './feature/_feature_memo.csv'\n",
        "        if not os.path.isfile(file_path):\n",
        "            with open(file_path, 'w') as f:pass\n",
        "        with open(file_path, 'r+', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "            lines = [line.strip() for line in lines]\n",
        "            col = [line for line in lines if line.split(',')[0] == self.name]\n",
        "            if len(col) != 0:\n",
        "                return\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([self.name, self.__doc__])\n",
        "\n",
        "# モデル定義の基底クラス\n",
        "class ModelBase:\n",
        "    def __init__(self, run_name, params=None):\n",
        "        self.run_name = run_name\n",
        "        self.params = params\n",
        "        self.model = None\n",
        "        self.y_pred = None\n",
        "\n",
        "    def train(self, tr_x, tr_y):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def predict(self, x):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def save_model(self):\n",
        "        pickle.dump(self.model, open(f'./model/{self.run_name}.pkl', 'wb'))\n",
        "\n",
        "    def load_model(self):\n",
        "        self.model = pickle.load(open(f'./model/{self.run_name}.pkl', 'rb'))\n"
      ],
      "metadata": {
        "id": "ZIl1rxp3KyIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## runner.py\n",
        "- 学習・推論を実行するクラス"
      ],
      "metadata": {
        "id": "xS2YNvuAPrhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Runner:\n",
        "    def __init__(self, run_name, model_cls, features, target, params, metric, n_fold=4):\n",
        "        \"\"\"\n",
        "        run_name  : str, 実行名\n",
        "        model_cls : class, モデルクラス\n",
        "        features  : list, 特徴量のリスト(ex. ['feat1', 'feat2', ...])\n",
        "        target    : str, 目的変数\n",
        "        params    : dict, モデルのハイパーパラメータ\n",
        "        metric    : func, モデルの評価指標\n",
        "        n_fold    : int, foldの個数\n",
        "        \"\"\"\n",
        "        self.run_name = run_name\n",
        "        self.model_cls = model_cls\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.params = params\n",
        "        self.metric = metric\n",
        "        self.n_fold = n_fold\n",
        "        self.STDOUT = sys.stdout\n",
        "\n",
        "        self.logger(f'features: {self.features}')\n",
        "        self.logger(f'params: {self.params}')\n",
        "\n",
        "    # 1fold分の学習\n",
        "    def train_fold(self, i_fold):\n",
        "        validation = (i_fold != 'all')\n",
        "        train_x = self.load_x_train()\n",
        "        train_y = self.load_y_train()\n",
        "\n",
        "        if validation:\n",
        "            # バリデーションデータの分割\n",
        "            tr_idx, va_idx = self.load_index_fold(i_fold)\n",
        "            tr_x, tr_y = train_x.iloc[tr_idx], train_y.iloc[tr_idx]\n",
        "            va_x, va_y = train_x.iloc[va_idx], train_y.iloc[va_idx]\n",
        "\n",
        "            # モデルの学習\n",
        "            model = self.build_model(i_fold)\n",
        "            model.train(tr_x, tr_y)\n",
        "\n",
        "            # バリデーションデータに対する予測と評価\n",
        "            va_pred = model.predict(va_x)\n",
        "            score = self.metric(va_y, va_pred)\n",
        "\n",
        "            return model, va_idx, va_pred, score\n",
        "        else:\n",
        "            # モデルの学習\n",
        "            model = self.build_model(i_fold)\n",
        "            model.train(train_x, train_y)\n",
        "\n",
        "            return model, None, None, None\n",
        "\n",
        "    # クロスバリデーションでの学習\n",
        "    def run_train_cv(self):\n",
        "        va_idxes = []\n",
        "        va_preds = []\n",
        "        scores = []\n",
        "\n",
        "        for i_fold in range(self.n_fold):\n",
        "            # 学習\n",
        "            print(f'{self.run_name} - Fold {i_fold + 1}')\n",
        "            with open(f'./model/{self.run_name}_calc.log', 'a') as f:\n",
        "                sys.stdout = f\n",
        "                print(f'\\n---------- Fold {i_fold + 1} ({datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}) ----------\\n')\n",
        "                model, va_idx, va_pred, score = self.train_fold(i_fold)\n",
        "            sys.stdout = self.STDOUT\n",
        "            # モデルの保存\n",
        "            model.save_model()\n",
        "            # 結果を保持\n",
        "            va_idxes.append(va_idx)\n",
        "            va_preds.append(va_pred)\n",
        "            scores.append(score)\n",
        "            # ログ出力\n",
        "            print(f'Fold {i_fold} Score: {score}')\n",
        "            self.logger(f'Fold {i_fold} Score: {score}')\n",
        "\n",
        "        # 各foldの結果をまとめる\n",
        "        va_idxes = np.concatenate(va_idxes)\n",
        "        va_preds = np.concatenate(va_preds, axis=0)[np.argsort(va_idxes)]\n",
        "\n",
        "        # CVスコア(平均値)の表示\n",
        "        print(f'{self.run_name} - training cv - score {np.mean(scores)}')\n",
        "        self.logger(f'{self.run_name} - training cv - score {np.mean(scores)}')\n",
        "\n",
        "    # 各foldのモデルをアンサンブルして予測\n",
        "    def run_predict_cv(self):\n",
        "        test_x = self.load_x_test()\n",
        "        preds = []\n",
        "\n",
        "        for i_fold in range(self.n_fold):\n",
        "            # 学習済みモデルの読み込み\n",
        "            model = self.build_model(i_fold)\n",
        "            model.load_model()\n",
        "            # 予測\n",
        "            pred = model.predict(test_x)\n",
        "            preds.append(pred)\n",
        "\n",
        "        # 各foldの結果の平均をとる\n",
        "        preds = np.mean(preds, axis=0)\n",
        "\n",
        "        return preds\n",
        "\n",
        "    # 全学習データで学習\n",
        "    def run_train_all(self):\n",
        "        model, _, _, _ = self.train_fold('all')\n",
        "        model.save_model()\n",
        "\n",
        "    # run_train_allで学習したモデルで予測\n",
        "    def run_predict_all(self):\n",
        "        test_x = self.load_x_test()\n",
        "\n",
        "        model = self.build_model('all')\n",
        "        model.load_model()\n",
        "        preds = model.predict(test_x)\n",
        "\n",
        "        return preds\n",
        "\n",
        "    # モデルを作成(インスタンス化)\n",
        "    def build_model(self, i_fold):\n",
        "        run_fold_name = f'{self.run_name}-{i_fold}'\n",
        "        return self.model_cls(run_fold_name, self.params)\n",
        "\n",
        "    # foldを指定して対応するindexを返す\n",
        "    def load_index_fold(self, i_fold):\n",
        "        train_y = self.load_y_train()\n",
        "        dummy_x = np.zeros(len(train_y))\n",
        "        skf = StratifiedKFold(n_splits=self.n_fold, shuffle=True)\n",
        "        return list(skf.split(dummy_x, train_y))[i_fold]\n",
        "\n",
        "    # 学習データの特徴量を読み込み\n",
        "    def load_x_train(self):\n",
        "        x_train = pd.read_pickle(Config.train_path)\n",
        "        feat_origin = [feat for feat in self.features if feat in x_train.columns]\n",
        "        feat_generated = [feat for feat in self.features if feat not in x_train.columns]\n",
        "        if len(feat_generated) > 0:\n",
        "            train_generated = pd.concat([pd.read_pickle(f'./feature/{feat}_train.pkl') for feat in feat_generated], axis=1)\n",
        "            x_train = pd.concat([x_train[feat_origin], train_generated], axis=1)\n",
        "        else:\n",
        "            x_train = x_train[feat_origin]\n",
        "        return x_train\n",
        "\n",
        "    # 学習データの目的変数を読み込み\n",
        "    def load_y_train(self):\n",
        "        return pd.read_pickle(Config.train_path)[self.target]\n",
        "\n",
        "    # テストデータの特徴量を読み込み\n",
        "    def load_x_test(self):\n",
        "        x_test = pd.read_pickle(Config.test_path)\n",
        "        feat_origin = [feat for feat in self.features if feat in x_test.columns]\n",
        "        feat_generated = [feat for feat in self.features if feat not in x_test.columns]\n",
        "        if len(feat_generated) > 0:\n",
        "            test_generated = pd.concat([pd.read_pickle(f'./feature/{feat}_test.pkl') for feat in feat_generated], axis=1)\n",
        "            x_test = pd.concat([x_test[feat_origin], test_generated], axis=1)\n",
        "        else:\n",
        "            x_test = x_test[feat_origin]\n",
        "        return x_test\n",
        "\n",
        "    def logger(self, text):\n",
        "        with open(f'./model/{self.run_name}_calc.log', 'a') as f:\n",
        "            sys.stdout = f\n",
        "            print(text)\n",
        "        sys.stdout = self.STDOUT"
      ],
      "metadata": {
        "id": "aADRoaDOP1Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## feature.py\n",
        "`base.py`のFeatureクラスを継承して、`create_features()`メソッドで特徴量を作成する。"
      ],
      "metadata": {
        "id": "8lU7BRhjTJ_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量を定義 ------------------------------\n",
        "class loan_amt_PER_term(Feature):\n",
        "    \"\"\"返済期間1年あたりの借入総額\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def create_features(self):\n",
        "        df_all = pd.concat([self.train, self.test])\n",
        "        df_all[self.name] = df_all['loan_amnt'] / df_all['term']\n",
        "        self.train = df_all[~df_all['loan_status'].isnull()][[self.name]]\n",
        "        self.test = df_all[df_all['loan_status'].isnull()][[self.name]]"
      ],
      "metadata": {
        "id": "PGYG3fleTPsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model.py\n",
        "`base.py`のModelクラスを継承して、`train()`,`predict()`,`save_model()`を定義する。"
      ],
      "metadata": {
        "id": "zCWb1Q0-TNNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使いたいモデルを定義 ------------------------\n",
        "class ModelLGBM(ModelBase):\n",
        "    \"\"\"LightGBM\"\"\"\n",
        "    def __init__(self, run_name ,params=None):\n",
        "        super().__init__(run_name, params)\n",
        "\n",
        "    def train(self, tr_x, tr_y):\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        tr_x, va_x, tr_y, va_y = train_test_split(tr_x, tr_y, train_size=0.8)\n",
        "        pos_rate = tr_y.value_counts()[1] / len(tr_y)\n",
        "        lgb_train = lgb.Dataset(tr_x, tr_y, weight=np.where(tr_y==1,1/pos_rate, 1/(1-pos_rate)))  # 重みづけ\n",
        "        lgb_eval = lgb.Dataset(va_x, va_y, reference=lgb_train)\n",
        "        self.model = lgb.train(self.params,\n",
        "                               lgb_train,\n",
        "                               valid_sets=lgb_eval,\n",
        "                               callbacks=[lgb.early_stopping(stopping_rounds=10)]\n",
        "                               )\n",
        "\n",
        "    def predict(self, x):\n",
        "        self.y_pred = self.model.predict(x)\n",
        "        return self.y_pred\n",
        "\n",
        "    def save_model(self):\n",
        "        pickle.dump(self.model, open(f'./model/{self.run_name}.pkl', 'wb'))\n",
        "        # 特徴量重要度のプロットも保存\n",
        "        lgb.plot_importance(self.model)\n",
        "        plt.savefig(f'./model/{self.run_name}_feature_importance.png')\n",
        "\n",
        "class ModelLR(ModelBase):\n",
        "    \"\"\"ロジスティック回帰\"\"\"\n",
        "    def __init__(self, run_name, params=None):\n",
        "        super().__init__(run_name, params)\n",
        "        self.model = LogisticRegression(**self.params)\n",
        "\n",
        "    def train(self, tr_x, tr_y, va_x=None, va_y=None):\n",
        "        self.model.fit(tr_x, tr_y)\n",
        "\n",
        "    def predict(self, x):\n",
        "        self.y_pred = self.model.predict_proba(x)[:, 1]\n",
        "        return self.y_pred\n",
        "\n",
        "class ModelRFC(ModelBase):\n",
        "    \"\"\"ランダムフォレスト\"\"\"\n",
        "    def __init__(self, run_name, params=None):\n",
        "        super().__init__(run_name, params)\n",
        "        self.model = RandomForestClassifier(**self.params)\n",
        "\n",
        "    def train(self, tr_x, tr_y, va_x=None, va_y=None):\n",
        "        self.model.fit(tr_x, tr_y)\n",
        "\n",
        "    def predict(self, x):\n",
        "        self.y_pred = self.model.predict_proba(x)[:, 1]\n",
        "        return self.y_pred"
      ],
      "metadata": {
        "id": "fIqjfqPHTMOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN.py\n",
        "実行フェーズ"
      ],
      "metadata": {
        "id": "OGlVIB7kSvDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 初回のみ実行\n",
        "Config().make_dir()"
      ],
      "metadata": {
        "id": "JIQe_QTASxbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量を作成・保存 ----------------------\n",
        "feat_cls = [loan_amt_PER_term]\n",
        "\n",
        "for feat_cl in feat_cls:\n",
        "    if os.path.isfile(f'./feature/{feat_cl.__name__}_train.pkl'): # すでに作成した特徴量はskip\n",
        "        print(f'[{feat_cl.__name__}] is already exist.')\n",
        "        continue\n",
        "    feat = feat_cl()\n",
        "    feat.run().save()\n",
        "    feat.create_memo()"
      ],
      "metadata": {
        "id": "bE0-YnRAS78e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量 ----------------------------------\n",
        "features = ['loan_amnt', 'term', 'interest_rate', 'grade',\n",
        "            'employment_length', 'credit_score', 'purpose_car',\n",
        "            'purpose_credit_card', 'purpose_debt_consolidation',\n",
        "            'purpose_home_improvement', 'purpose_house', 'purpose_major_purchase',\n",
        "            'purpose_medical', 'purpose_moving', 'purpose_other',\n",
        "            'purpose_renewable_energy', 'purpose_small_business',\n",
        "            'purpose_vacation', 'purpose_wedding', 'application_type_Individual',\n",
        "            'application_type_Joint App', 'loan_amt_PER_term']\n",
        "\n",
        "# 目的変数 --------------------------------\n",
        "target = 'loan_status'\n",
        "\n",
        "# 実行名 ----------------------------------\n",
        "run_name = 'run001'\n",
        "\n",
        "# パラメータ ------------------------------\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_log_loss',\n",
        "    'num_iterations': 10000\n",
        "}\n",
        "\n",
        "# 学習 ------------------------------------\n",
        "# モデル、評価関数を適宜変更してください。\n",
        "runner = Runner(run_name, ModelLGBM, features, target, params, f1_score_prob)\n",
        "runner.run_train_cv()\n",
        "preds = runner.run_predict_cv()\n",
        "\n",
        "# submission.csvの作成 -----------------------------------------------------\n",
        "# 提出形式に応じて書き換えてください。\n",
        "threshold = 0.5\n",
        "ids = pd.read_pickle(Config.test_path)['id']\n",
        "sub = pd.DataFrame({'id': ids, 'prob': np.where(preds>threshold, 1, 0)})\n",
        "sub.to_csv(f'./submission/submission_{run_name}.csv', index=False, header=False)"
      ],
      "metadata": {
        "id": "byN5n1T0Wsyo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}